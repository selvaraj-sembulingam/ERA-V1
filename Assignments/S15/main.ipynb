{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/selvaraj-sembulingam/ERA-V1.git\n",
        "%cd ERA-V1/Assignments/S15"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-09-01T16:46:19.858369Z",
          "iopub.execute_input": "2023-09-01T16:46:19.859346Z",
          "iopub.status.idle": "2023-09-01T16:46:37.115480Z",
          "shell.execute_reply.started": "2023-09-01T16:46:19.859301Z",
          "shell.execute_reply": "2023-09-01T16:46:37.114315Z"
        },
        "trusted": true,
        "id": "2QFyNRTLVBjl",
        "outputId": "9b4a5e48-03b9-41ac-dba6-ebdcc2572fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'ERA-V1'...\nremote: Enumerating objects: 1899, done.\u001b[K\nremote: Counting objects: 100% (797/797), done.\u001b[K\nremote: Compressing objects: 100% (507/507), done.\u001b[K\nremote: Total 1899 (delta 365), reused 642 (delta 282), pack-reused 1102\u001b[K\nReceiving objects: 100% (1899/1899), 246.87 MiB | 18.75 MiB/s, done.\nResolving deltas: 100% (814/814), done.\n/kaggle/working/ERA-V1/Assignments/S15\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets tokenizers torchmetrics pytorch_lightning"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T16:47:07.247437Z",
          "iopub.execute_input": "2023-09-01T16:47:07.247830Z",
          "iopub.status.idle": "2023-09-01T16:47:20.174166Z",
          "shell.execute_reply.started": "2023-09-01T16:47:07.247801Z",
          "shell.execute_reply": "2023-09-01T16:47:20.172890Z"
        },
        "trusted": true,
        "id": "DwMmYSbuVBjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import warnings\n",
        "import os\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "\n",
        "from datamodule import OpusBookDataModule\n",
        "from litmodel import LightningTransformer\n",
        "from config import get_config\n",
        "cfg = get_config()\n",
        "\n",
        "\n",
        "from model import build_transformer\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  torch.cuda.empty_cache()\n",
        "  # os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:12240\"\n",
        "\n",
        "  pl.seed_everything(1, workers=True)\n",
        "  data_module = OpusBookDataModule(cfg)\n",
        "  tokenizer_src, tokenizer_tgt = data_module.setup(stage=\"None\")\n",
        "  model = build_transformer(\n",
        "        tokenizer_src.get_vocab_size(),\n",
        "        tokenizer_tgt.get_vocab_size(),\n",
        "        cfg[\"seq_len\"],\n",
        "        cfg[\"seq_len\"],\n",
        "        d_model=cfg[\"d_model\"],\n",
        "  )\n",
        "\n",
        "  litmodel = LightningTransformer(model=model, learning_rate=cfg[\"lr\"], tokenizer_src=tokenizer_src, tokenizer_tgt=tokenizer_tgt, max_len=cfg[\"seq_len\"], num_examples=2)\n",
        "\n",
        "\n",
        "  trainer = pl.Trainer(\n",
        "      max_epochs=10,\n",
        "      deterministic=True,\n",
        "      logger=True,\n",
        "      enable_model_summary=False,\n",
        "      log_every_n_steps=1,\n",
        "      precision=16\n",
        "  )\n",
        "  trainer.fit(litmodel, data_module)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T16:47:20.204668Z",
          "iopub.execute_input": "2023-09-01T16:47:20.205111Z",
          "iopub.status.idle": "2023-09-01T19:48:24.290618Z",
          "shell.execute_reply.started": "2023-09-01T16:47:20.205081Z",
          "shell.execute_reply": "2023-09-01T19:48:24.289631Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "33b2fe2b5575400c8839c11679398678",
            "aefe9f9c760a4b79a8f9fe052d400b67",
            "1458f7685163401ea94ccfc225d648de",
            "",
            "6c076810ab3644f48908abc5d883db81"
          ]
        },
        "id": "6FsPaUpZVBjt",
        "outputId": "95cdf346-4d3b-4e7e-88c0-bdc33f523ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.40k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33b2fe2b5575400c8839c11679398678"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/7.98k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aefe9f9c760a4b79a8f9fe052d400b67"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset opus_books/en-it (download: 3.14 MiB, generated: 8.58 MiB, post-processed: Unknown size, total: 11.72 MiB) to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/3.30M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1458f7685163401ea94ccfc225d648de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset opus_books downloaded and prepared to /root/.cache/huggingface/datasets/opus_books/en-it/1.0.0/e8f950a4f32dc39b7f9088908216cd2d7e21ac35f893d04d39eb594746af2daf. Subsequent calls will reuse this data.\nMax length of source sentence: 309\nMax length of target sentence: 274\nMax length of source sentence: 309\nMax length of target sentence: 274\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: Were you jealous, Jane?\"\n    TARGET: Eravate gelosa, Jane?\n PREDICTED: godono godono godono godono godono godono godono consigliò consigliò consigliò consigliò consigliò consigliò consigliò consigliò consigliò godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono consigliò circostante consigliò godono godono godono godono godono godono godono godono godono godono consigliò circostante consigliò godono godono godono godono godono godono godono godono godono consigliò circostante consigliò circostante consigliò circostante consigliò circostante consigliò circostante metà metà metà metà metà metà metà consigliò godono godono consigliò consigliò cranio metà metà metà metà metà godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono circostante circostante circostante circostante metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà consigliò consigliò consigliò metà consigliò metà godono godono metà metà metà metà godono godono godono godono godono godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà metà consigliò godono godono godono godono godono godono godono godono godono godono godono godono godono consigliò metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono godono godono metà metà metà godono godono godono godono godono metà metà metà metà metà consigliò godono consigliò godono consigliò metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono godono godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono godono metà metà metà metà godono godono godono godono godono metà metà metà godono godono godono godono godono godono godono metà metà metà godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono metà metà metà metà godono godono godono godono godono godono godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà godono godono\n----------\n    SOURCE: Not one of her children had crawled like that.\n    TARGET: Neanche uno dei suoi bambini s’era trascinato così.\n PREDICTED: godono godono godono godono godono godono godono godono godono godono godono godono godono consigliò godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono godono circostante circostante godono godono godono godono godono godono matrimoniale matrimoniale matrimoniale matrimoniale matrimoniale consigliò circostante consigliò funzionari matrimoniale funzionari matrimoniale matrimoniale matrimoniale godono godono godono funzionari cranio funzionari matrimoniale matrimoniale matrimoniale matrimoniale matrimoniale metà matrimoniale matrimoniale matrimoniale matrimoniale matrimoniale matrimoniale metà metà funzionari matrimoniale matrimoniale matrimoniale cranio cranio cranio metà metà metà matrimoniale metà cranio funzionari cranio godono godono godono godono funzionari funzionari funzionari funzionari funzionari metà funzionari metà funzionari matrimoniale matrimoniale matrimoniale metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono godono metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà godono godono godono metà metà metà metà metà funzionari matrimoniale matrimoniale fermatosi metà metà metà metà metà metà matrimoniale matrimoniale matrimoniale matrimoniale metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà fermatosi fermatosi fermatosi fermatosi fermatosi metà metà metà metà fermatosi fermatosi fermatosi metà metà metà metà metà fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi fermatosi godono godono godono godono metà fermatosi fermatosi fermatosi metà godono godono selvatiche metà fermatosi fermatosi metà fermatosi metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà fermatosi fermatosi metà metà metà metà metà metà metà metà metà metà metà metà metà metà metà\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Training: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c076810ab3644f48908abc5d883db81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: 'Papa!' exclaimed Kitty and closed his mouth with her hands.\n    TARGET: — Papà — gridò Kitty e gli chiuse la bocca con le mani.\n PREDICTED: — Ma , — disse Levin , e si disse , e si fermò .\n----------\n    SOURCE: \"Thank you: I shall do: I have no broken bones,--only a sprain;\" and again he stood up and tried his foot, but the result extorted an involuntary \"Ugh!\"\n    TARGET: — Grazie, non ho nulla di rotto, si tratta di una storta. Volle provarsi un'altra volta a camminare, ma involontariamente gettò un grido.\n PREDICTED: — Sì , — disse , — mi disse , — mi disse , — e la signora , — e la signora , e la signora , e la signora .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: At the very moment that Vronsky thought it time to pass Makhotin, Frou-Frou, understanding what was in his mind, without any urging, considerably increased her speed and began to draw nearer to Makhotin on the side where it was most advantageous to pass him – the side of the rope, Makhotin would not let her pass that side.\n    TARGET: Proprio nel momento in cui Vronskij pensava di oltrepassare Machotin, Frou-Frou stessa, intuendone il pensiero, senza essere stimolata, accelerò notevolmente il galoppo, e cominciò ad avvicinarsi a Machotin dal lato più conveniente, cioè rasente la corda. Machotin però non lasciava andare la corda.\n PREDICTED: In quel momento , Levin , che era stato di lui , Levin , che , Levin , che , Levin , che , in quel momento , che , in quel momento , in un ’ altra parte , che , in cui , in cui , in un ’ altra volta , che non si era stato in un ’ altra parte di cui si era stato in un ’ altra parte di cui si era stato di un ’ altra parte di cui non si era stato in un ’ altra parte di cui si era stato di cui , e di cui il suo modo di cui si era stato in un ’ altra parte di cui si era stato di un ’ altra parte di cui il suo modo di un ’ altra parte di cui , e , e , e , e , e che , e , e , e di un ’ altra parte di cui il suo momento , e di cui il suo momento , e di cui il suo momento , e che il suo modo di un momento , e di cui si era stato di cui si era stato di cui il suo modo di cui si era stato di cui si era stato di cui era stato di cui , e di cui si era stato di cui , e di cui , e , e , e di cui , e di cui si era stato di cui , e di cui si era stato di cui si era stato di cui si era stato di cui , e , e che , e che , e che , e che , e che , e che , e che , e che , e che , e che , e che , e , e , e che , e , e , e che , e che , e , e , e che , e che , e , e , e , e , e , e , e\n----------\n    SOURCE: It was old and beginning to decay.\n    TARGET: Ma ormai anch’essa era cadente e ammuffita.\n PREDICTED: Era un ’ altra cosa .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: 'You will allow me to listen?' he asked.\n    TARGET: — Mi permettete di ascoltare? — chiese.\n PREDICTED: — Avete bisogno di me ? — domandò .\n----------\n    SOURCE: \"Well?\" I said, as he again paused--\"proceed.\"\n    TARGET: — Bene, — dissi, quando tacque, — continuate.\n PREDICTED: — Ebbene , — disse , — e io sono felice .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: I don't very well know what I did with my hands, but he called me \"Rat!\n    TARGET: Non so dire quello che io facessi con le mani, ma John mi chiamava: \"Talpa!\n PREDICTED: Non so che cosa mi , ma mi misi a piangere , ma mi disse :\n----------\n    SOURCE: So I asked him if he would, and if we might venture over in her. “Yes,” he said, “we venture over in her very well, though great blow wind.”\n    TARGET: Gli chiesi pertanto se voleva e se dovevamo arrischiarci sovr’essa. — «Sì, rispose, potere e volere, anche se soffiar vento grande .»\n PREDICTED: E se fosse andato a me , e se fosse andato a casa , se ne , , , , il fuoco , disse : — « « « , come se ne , come se ne , come un vento di vento .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: He was dressed now: he still looked pale, but he was no longer gory and sullied.\n    TARGET: Era vestito e mi parve debolissimo, ma su di lui non c'era nessuna traccia di sangue.\n PREDICTED: Egli era troppo forte , ma non era più forte , ma non era più bello .\n----------\n    SOURCE: Having lived most of his life in the country and in close contact with the peasants, Levin always felt, at this busy time, that this general stimulation of the peasants communicated itself to him.\n    TARGET: Avendo vissuto la maggior parte della sua vita in campagna e in rapporti intimi con la gente di campagna, Levin, nel periodo di lavoro, sentiva sempre che quella generale eccitazione del popolo si comunicava anche a lui.\n PREDICTED: sempre più la vita di vita e di campagna , Levin si sentiva sempre più forte , che Levin sentiva che , in questo tempo , in questo tempo , era con l ’ azienda dell ’ azienda .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: \"You see now, my queenly Blanche,\" began Lady Ingram, \"she encroaches. Be advised, my angel girl--and--\"\n    TARGET: — Vedete, mia regale Bianca, essa diventa sempre più esigente.\n PREDICTED: — Avete fatto bene , signorina , — continuò Bianca , — venite a mio zio , e mi ha detto :\n----------\n    SOURCE: \"Well, I would rather die yonder than in a street or on a frequented road,\" I reflected. \"And far better that crows and ravens--if any ravens there be in these regions--should pick my flesh from my bones, than that they should be prisoned in a workhouse coffin and moulder in a pauper's grave.\"\n    TARGET: — Ebbene, — dissi a me stessa, — preferisco morir qui piuttosto che su una strada frequentata, e se vi sono corvi nel vicinato preferisco che essi si pascano delle mie carni piuttosto che sapere il mio corpo rinchiuso nella bara di un ospedale e sepolto nella fossa dei poveri.\n PREDICTED: — Ebbene , vorrei esser buona , o in mezzo a un paese o in mezzo a una casa , — mi disse , — e se mi sarei stato meglio che mi in Inghilterra , e se mi sarei stato un di in Inghilterra , e se mi in una .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: Levin turned round.\n    TARGET: Levin si voltò a guardare.\n PREDICTED: Levin si voltò .\n----------\n    SOURCE: Now hear how the deacon will roar, \"Wives, obey your husbands\"!'\n    TARGET: Su, senti come urla il diacono: “che tema suo marito”.\n PREDICTED: Ora , come un sorriso , i vostri diritti , le quali la vostra volontà .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: \"Mr. Wood is in the vestry, sir, putting on his surplice.\"\n    TARGET: — Il signor Wood è giunto e si veste.\n PREDICTED: — Il signor Rochester è in mezzo al sicuro , signore , e nel suo sangue .\n----------\n    SOURCE: 'WELL, HAVE YOU HAD A GOOD TIME?' she asked, coming out to meet him with a meek and repentant look on her face.\n    TARGET: — Be’, c’è stata allegria? — chiese lei, uscendogli incontro con un’espressione colpevole e mansueta nel viso.\n PREDICTED: — Be ’, tu , sei stato fatto da te ? — ella disse , avvicinandosi a lui con un gesto energico , con un gesto spaventato e preoccupato .\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: 'Yes, yes!'\n    TARGET: — Sì, sì.\n PREDICTED: — Sì , sì !\n----------\n    SOURCE: What are you?\n    TARGET: Cosa mai siete?\n PREDICTED: Che cosa avete ?\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Validation: 0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----------\n    SOURCE: [Long argument between Harris and Harris's friend as to what Harris is really singing.\n    TARGET: (Lunga discussione fra Harris e l’amico di Harris su ciò che Harris realmente canti.\n PREDICTED: di Harris e di , come Harris di Harris , che è veramente veramente .\n----------\n    SOURCE: What an appetite I get in the country, wonderful!\n    TARGET: Che appetito m’è venuto in campagna, un prodigio!\n PREDICTED: Che gioia ho fatto in campagna , in campagna !\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_filename = \"transformer.pth\"\n",
        "torch.save(\n",
        "            {\n",
        "                \"epoch\": \"10\",\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "            },\n",
        "            model_filename,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-01T19:48:56.910694Z",
          "iopub.execute_input": "2023-09-01T19:48:56.911074Z",
          "iopub.status.idle": "2023-09-01T19:48:57.269767Z",
          "shell.execute_reply.started": "2023-09-01T19:48:56.911045Z",
          "shell.execute_reply": "2023-09-01T19:48:57.268735Z"
        },
        "trusted": true,
        "id": "xKwz2R9xVBju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pp0GBWCVBju"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}